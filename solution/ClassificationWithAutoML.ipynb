{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1633965293526
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Workspace, Dataset, Experiment, Run\n",
        "from azureml.core.compute import ComputeTarget,AmlCompute\n",
        "from azureml.core.model import Model, InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice, Webservice\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "from sklearn.model_selection import train_test_split\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.widgets import RunDetails\n",
        "import logging, requests,json\n",
        "import urllib.request\n",
        "\n",
        "# Get current workspace info\n",
        "ws = Workspace.from_config()\n",
        "\n",
        "# Since the dataset is already uploaded and listed in the ws\n",
        "# retrieve the dataset by name\n",
        "dataset = Dataset.get_by_name(ws, name='wine')\n",
        "\n",
        "# For easier manipulation, let's transform the tabular dataset into\n",
        "# a pandas dataframe\n",
        "df = dataset.to_pandas_dataframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1633962736053
        }
      },
      "outputs": [],
      "source": [
        "# Splitting the dataset in train and test for further use\n",
        "train_data, test_data = train_test_split(df, test_size=0.1, random_state=42)\n",
        "# Defining the label\n",
        "label = \"quality\"\n",
        "\n",
        "# Since AutoML supports only Tabular Dataset, the train dataset needs to be converted\n",
        "# in the correct format. \n",
        "# First let's retrieve the datastore \n",
        "datastore = ws.get_default_datastore()\n",
        "# And use the sdk to register and convert from pandas to Tabular \n",
        "train_dataset = Dataset.Tabular.register_pandas_dataframe(train_data,datastore,'wine_train_dataset',description='Train dataset for wine')\n",
        "#test_dataset = Dataset.Tabular.register_pandas_dataframe(test_data,datastore,'wine_test_dataset',description='Test dataset for wine')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1633962741270
        }
      },
      "outputs": [],
      "source": [
        "# AutoML need a compute target to run\n",
        "# You can use an already existing one or \n",
        "# you can create a new one\n",
        "\n",
        "compute_name = 'your_compute_instance'\n",
        "\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws,name=compute_name)\n",
        "    print('Found existing compute resource, using it')\n",
        "except ComputeTargetException:\n",
        "    compute_config = AmlCompute.provisioning_configuration(\n",
        "        vm_size= 'STANDARD_D12_V2', #you can change the size of the vm\n",
        "        max_nodes=2 #you can change the max number of nodes\n",
        "    )\n",
        "    compute_target = ComputeTarget.create(ws, compute_name, compute_config)\n",
        "\n",
        "compute_target.wait_for_completion(show_output=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1633962741482
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Automl config where you define the taks type,\n",
        "# the primary metric, the training dataset,\n",
        "# the label, the compute target.   \n",
        "\n",
        "automl_config = AutoMLConfig(\n",
        "                                 task='classification',\n",
        "                                 debug_log ='automl_notebook_errors.log',\n",
        "                                 primary_metric='AUC_weighted',\n",
        "                                 experiment_timeout_minutes=30,\n",
        "                                 training_data=train_dataset,\n",
        "                                 label_column_name=label,\n",
        "                                 compute_target = compute_target,\n",
        "                                 n_cross_validations=5,\n",
        "                                 verbosity=logging.INFO,\n",
        "                                 featurization='auto',\n",
        "                                 enable_voting_ensemble=False,\n",
        "                                 enable_stack_ensemble=False\n",
        "                                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1633964757681
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# To run AutoML an experiment is required\n",
        "experiment_name = 'AutoML-Notebook'\n",
        "experiment = Experiment(ws, experiment_name)\n",
        "\n",
        "# Now with the experiment create\n",
        "# we can submit the AutoML and it creates a run\n",
        "run = experiment.submit(automl_config, show_output=True)\n",
        "\n",
        "# The output of the run is the best model\n",
        "best_run, fitted_model = run.get_output()\n",
        "print(fitted_model.steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1633977301987
        }
      },
      "outputs": [],
      "source": [
        "# We can use the test dataset to check the performance \n",
        "# of the best model\n",
        "y_test = test_data.pop(\"quality\")\n",
        "\n",
        "y_classify = fitted_model.predict(test_data)\n",
        "\n",
        "print(\"Predicted:  \" + y_classify[:10] + \" Value: \" + y_test[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1633964759081
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Register the best model into Models\n",
        "model_name = best_run.properties['model_name']\n",
        "description = 'AutoML jupyter example'\n",
        "tags = None\n",
        "\n",
        "model = run.register_model(model_name = model_name, \n",
        "                                  description = description, \n",
        "                                  tags = tags)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1633964840337
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# AutoML auto-generates the score.py file\n",
        "# which it's useful when we want to deploy the model\n",
        "# as a web service. We can download it and use it as an\n",
        "# entry point for the API\n",
        "\n",
        "script_file_name = 'score.py'\n",
        "file_dwn = best_run.download_file('./outputs/scoring_file_v_1_0_0.py', script_file_name)\n",
        "\n",
        "print(file_dwn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1633965107431
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Set the model configurations: environment and entry script\n",
        "inference_config = InferenceConfig(environment = best_run.get_environment(), \n",
        "                                   entry_script = './score.py')\n",
        "\n",
        "# Set the container configurations\n",
        "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 2, \n",
        "                                               memory_gb = 4, \n",
        "                                               tags = {'type': \"automl-jupyter\"},\n",
        "                                               description = \"Automl jupyter sample service\")\n",
        "\n",
        "aci_service_name = 'automl-jupyter-model'\n",
        "print(aci_service_name)\n",
        "\n",
        "# Deploy the model into the ACI\n",
        "aci_service = Model.deploy(ws, aci_service_name, [model], inference_config, aciconfig)\n",
        "aci_service.wait_for_deployment(True)\n",
        "print(aci_service.state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1633979822534
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Test the container deployed with a data example.\n",
        "\n",
        "scoring_uri = aci_service.scoring_uri\n",
        "\n",
        "# Request data goes here\n",
        "data = {\"data\": [\n",
        "    {\n",
        "      \"fixed acidity\": 8.8,\n",
        "      \"volatile acidity\": 0.32,\n",
        "      \"citric acid\": 0.57,\n",
        "      \"residual sugar\": 2.3,\n",
        "      \"chlorides\": 0.069,\n",
        "      \"free sulfur dioxide\": 29,\n",
        "      \"total sulfur dioxide\": 37,\n",
        "      \"density\": 0.997,\n",
        "      \"pH\": 3.15,\n",
        "      \"sulphates\": 0.61,\n",
        "      \"alcohol\": 9.6\n",
        "    }\n",
        "  ],\n",
        "  \"method\": \"predict\"\n",
        "  }\n",
        "\n",
        "input_data = json.dumps(data)\n",
        "\n",
        "# Set the content type\n",
        "headers = {'Content-Type': 'application/json'}\n",
        "\n",
        "# Make the request and display the response\n",
        "resp = requests.post(scoring_uri, input_data, headers=headers)\n",
        "\n",
        "print(resp.status_code)\n",
        "print(\"The wine submitted is \" + resp.json())"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "962790a903f06945bedf793afb3bd0222459049c450f25bfc83e865d4f25a357"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('security': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
