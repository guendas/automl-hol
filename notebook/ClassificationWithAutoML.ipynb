{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1633965293526
        }
      },
      "outputs": [],
      "source": [
        "from azureml.core import Workspace, Dataset, Experiment, Run\n",
        "from azureml.core.compute import ComputeTarget,AmlCompute\n",
        "from azureml.core.model import Model, InferenceConfig\n",
        "from azureml.core.webservice import AciWebservice, Webservice\n",
        "from azureml.core.compute_target import ComputeTargetException\n",
        "from sklearn.model_selection import train_test_split\n",
        "from azureml.train.automl import AutoMLConfig\n",
        "from azureml.widgets import RunDetails\n",
        "import logging, requests,json\n",
        "import urllib.request\n",
        "\n",
        "# First things first: the Workspace. You use the Workspace to experiment, train and deploy machine learning models.\n",
        "# You can create a brand new one from zero or you can get the configuration of the one you're using.\n",
        "# Are you able to find out how to gather the configuration of your current workspace?\n",
        "# \n",
        "# TIPS: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.workspace.workspace?view=azure-ml-py#\n",
        "\n",
        "ws = Workspace.#find the right method to gather the current workspace info\n",
        "\n",
        "# In this demo we already uploaded the dataset.\n",
        "# How can you use it and reference it in the code? \n",
        "# TIPS: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.dataset.dataset?view=azure-ml-py\n",
        "dataset = Dataset.#reference the dataset you uploaded before\n",
        "\n",
        "# Since all the imported dataset are formatted as Tabular,let's \n",
        "# transform the dataset into a pandas dataframe for easier use.\n",
        "df = dataset.to_pandas_dataframe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1633962736053
        }
      },
      "outputs": [],
      "source": [
        "# In every ML project, the first step we should do is to pre-process the data.\n",
        "# The dataset we are using is already pre-processed so we can skip this step\n",
        "# and get to the next one: splitting the dataset. \n",
        "\n",
        "# We'll split the dataset in train and test\n",
        "train_data, test_data = train_test_split(df, test_size=0.1, random_state=42)\n",
        "# We define the label variable, we'll need it for AutoML\n",
        "label = \"quality\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# AutoML is a great tool! Allows us to find quickly the best algorithm for our data.\n",
        "# It needs to be configured and we'll need a few things:\n",
        "# 1. Tabular train dataset\n",
        "# 2. Compute target that will be use to run our experiment\n",
        "# 3. An experiment to keep track of our training runs\n",
        "# 4. Configure the AutoML run\n",
        "\n",
        "# We split our dataset in train and test, but our dataset is of type \n",
        "# dataframe and not tabular. We need to convert it back to tabular to use it in our\n",
        "# AutoML config run. How can we do that? \n",
        "# First, we need to access the default datastore connected to the Workspace.\n",
        "# TIPS: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.workspace.workspace?view=azure-ml-py\n",
        "\n",
        "datastore = #How can you get the default datastore connected to your current workspace?\n",
        "\n",
        "# Now that we have the datastore, we just need to register our dataframe into a Tabular dataset.\n",
        "# We can give it a name and a description, after we register it we will be able to see it in our\n",
        "# Datasets tab. \n",
        "#TIPS: https://github.com/MicrosoftDocs/azure-docs/blob/master/articles/machine-learning/how-to-create-register-datasets.md#create-a-dataset-from-pandas-dataframe\n",
        "train_dataset = Dataset.#How can you create and register a dataframe into a Tabular dataset? \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1633962741270
        }
      },
      "outputs": [],
      "source": [
        "# We need now to define the compute instance we are going to use to run AutoML\n",
        "# To do so, we first need to give it a name. If you already created a compute resource\n",
        "# and want to use it, you can use that same name. \n",
        "# This code will check if the compute exists, if not it will create it \n",
        "\n",
        "compute_name = 'edit_here_your_compute_name' #Edit with your compute name\n",
        "\n",
        "try:\n",
        "    compute_target = ComputeTarget(workspace=ws,name=compute_name)\n",
        "    print('Found existing compute resource, using it')\n",
        "except ComputeTargetException:\n",
        "    compute_config = AmlCompute.provisioning_configuration(\n",
        "        vm_size= 'STANDARD_D12_V2', #Edit the vm_size if you prefer a bigger or smaller vm\n",
        "        max_nodes=2 #Edit number of nodes if you want to give different configurations\n",
        "    )\n",
        "    compute_target = ComputeTarget.create(ws, compute_name, compute_config)\n",
        "\n",
        "compute_target.wait_for_completion(show_output=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1633962741482
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Now we need to configure the AutoML run \n",
        "# To do so, we need to define:\n",
        "# - what kind of task we are trying to do\n",
        "# - which metric we will use to define how is our model performing \n",
        "# - experiment timeout (for the sake of the demo)\n",
        "# - the training tabular data\n",
        "# - the label\n",
        "# - the compute targe\n",
        "# - cross-validation number\n",
        "# TIPS: https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train\n",
        "# Automl config\n",
        "automl_config = AutoMLConfig(\n",
        "                                 task='type_of_task', # is it classification, regression or forecasting?\n",
        "                                 debug_log ='automl_notebook_errors.log',\n",
        "                                 primary_metric='AUC_weighted',\n",
        "                                 experiment_timeout_minutes=30,\n",
        "                                 training_data=#which is your training dataset?,\n",
        "                                 label_column_name=#which is the label?,\n",
        "                                 compute_target = #which is the target compute?,\n",
        "                                 n_cross_validations=5,\n",
        "                                 verbosity=logging.INFO,\n",
        "                                 featurization='auto',\n",
        "                                 enable_voting_ensemble=False,\n",
        "                                 enable_stack_ensemble=False\n",
        "                                )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1633964757681
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# It's time to set up our Experiment, which will contain all the runs and info on the training.\n",
        "# Give it a name that is significant for your training \n",
        "\n",
        "experiment_name = 'edit_experiment_name'#Edit the experiment name\n",
        "\n",
        "# Let's create the experiment in the current workspace. \n",
        "# TIPS: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.experiment?view=azure-ml-py\n",
        "experiment = Experiment #Create the experiment with the name you decided in the current workspace\n",
        "\n",
        "#Submit the experiment and get the created run\n",
        "run = experiment.# how can you submit the experiment using AutoML?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# After it finished running your data on the different algorithms\n",
        "# AutoML gives you the best run, the one with the best value on the metric\n",
        "# you defined in the configuration. \n",
        "# Can you retrieve the best run and the best model? \n",
        "# TIPS: https://docs.microsoft.com/en-us/python/api/azureml-train-automl-client/azureml.train.automl.run.automlrun?view=azure-ml-py\n",
        "best_run, fitted_model = #How can you retrieve the best run and the model? \n",
        "print(fitted_model.steps)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1633977301987
        }
      },
      "outputs": [],
      "source": [
        "# Before the deployment of the model, let's test it on our test data.\n",
        "# To check the performance\n",
        "\n",
        "# Drop the label column from the test dataframe\n",
        "y_test = test_data.pop(\"quality\")\n",
        "\n",
        "# Let's call the predict model method on the data and store predictions\n",
        "y_classify = fitted_model.predict(test_data)\n",
        "\n",
        "# Let's easily print the first 10 prediction and actual value to compare\n",
        "# You could even do some better analysis on this results\n",
        "print(\"Predicted:  \" + y_classify[:10] + \" Value: \" + y_test[:10])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1633964759081
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# We are almost done with our ML process! \n",
        "# We found the best model fitting our data and now we are close to deploying it and consume it!\n",
        "# As we said previously, we need first to register the model in the current workspace. \n",
        "# To keep track of the model and publish always the best version of it.\n",
        "# How can we do this step? \n",
        "# We get the model name, we add a description and we register it.\n",
        "#TIPS: https://docs.microsoft.com/en-us/azure/machine-learning/how-to-configure-auto-train\n",
        "\n",
        "#Model info\n",
        "model_name = #From the run, retrieve the model name\n",
        "description = 'AutoML jupyter example'\n",
        "tags = None\n",
        "\n",
        "#Register the model\n",
        "#TIPS: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run(class)?view=azure-ml-py\n",
        "model = run.#register the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1633964840337
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Last step to deploy our registered model is configure the web service we are going to consume.\n",
        "# Since it's going to be an api we need to define the script that will run when the API gets called\n",
        "# We can manually write the script or use an auto-generated script AutoML gives us. \n",
        "# We are going to retrieve and use the script.\n",
        "# TIPS: \n",
        "\n",
        "# Let's give a name to the script\n",
        "script_file_name = 'score.py'\n",
        "# The script we want to retrieve is at this path:\n",
        "# ./outputs/scoring_file_v_1_0_0.py\n",
        "# How would you retrieve it? \n",
        "#TIPS: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run(class)?view=azure-ml-py\n",
        "\n",
        "file_dwn = best_run.#retrieve the auto generated scoring file \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1633965107431
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# Finally the last step: deploy the model into a container\n",
        "# We have our script, we have the model registered. \n",
        "# Now let's consume and use the model. \n",
        "# To do so, we need to configurations:\n",
        "# 1. our environment and entry script\n",
        "# 2. the container instance we are going to use\n",
        "\n",
        "# Let's start from the environment configuration. \n",
        "# The model is ready and registered and the run has all the information we need. \n",
        "# TIPS: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.run(class)?view=azure-ml-py\n",
        "inference_config = InferenceConfig(environment = best_run.#get the environment info, \n",
        "                                   entry_script = './score.py') #we saved the script in the root folder, let's reference it\n",
        "\n",
        "#You can change the following configuration fo the container instance\n",
        "aciconfig = AciWebservice.deploy_configuration(cpu_cores = 2, \n",
        "                                               memory_gb = 4, \n",
        "                                               tags = {'type': \"automl-jupyter\"},\n",
        "                                               description = \"Automl jupyter sample service\")\n",
        "\n",
        "aci_service_name = 'automl-jupyter-model'\n",
        "print(aci_service_name)\n",
        "# It's time to deploy our model! How can you do it?\n",
        "#TIPS: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.model.model?view=azure-ml-py\n",
        "aci_service = #deploy the domdel\n",
        "aci_service.wait_for_deployment(True)\n",
        "print(aci_service.state)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1633979822534
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "# And now, let's consume and test our model with new data!\n",
        "# We need the scoring uri to call the service\n",
        "# TIPS: https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.webservice.aci.aciwebservice?view=azure-ml-py\n",
        "scoring_uri = # how can you retrieve the scoring uri?\n",
        "\n",
        "# Let's try sending this data\n",
        "data = {\"data\": [\n",
        "    {\n",
        "      \"fixed acidity\": 8.8,\n",
        "      \"volatile acidity\": 0.32,\n",
        "      \"citric acid\": 0.57,\n",
        "      \"residual sugar\": 2.3,\n",
        "      \"chlorides\": 0.069,\n",
        "      \"free sulfur dioxide\": 29,\n",
        "      \"total sulfur dioxide\": 37,\n",
        "      \"density\": 0.997,\n",
        "      \"pH\": 3.15,\n",
        "      \"sulphates\": 0.61,\n",
        "      \"alcohol\": 9.6\n",
        "    }\n",
        "  ],\n",
        "  \"method\": \"predict\"\n",
        "  }\n",
        "\n",
        "input_data = json.dumps(data)\n",
        "\n",
        "# Set the content type\n",
        "headers = {'Content-Type': 'application/json'}\n",
        "\n",
        "# Make the request and display the response\n",
        "resp = requests.post(scoring_uri, input_data, headers=headers)\n",
        "\n",
        "print(resp.status_code)\n",
        "print(\"The wine submitted is \" + resp.json())"
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "962790a903f06945bedf793afb3bd0222459049c450f25bfc83e865d4f25a357"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit ('security': conda)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
